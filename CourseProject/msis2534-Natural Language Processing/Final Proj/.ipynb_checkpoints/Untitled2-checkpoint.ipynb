{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AeQBM8zlGmNa"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('drive/MyDrive/heart_disease_health_indicators_BRFSS2015.csv')"
      ],
      "metadata": {
        "id": "DqoZ9Xx-K7OV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = data.copy()"
      ],
      "metadata": {
        "id": "FIkzpDRT5E5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "bZr8Rz1T5EAf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target = 'HeartDiseaseorAttack'\n",
        "ordinal_features = ['Education', 'Age', 'PhysHlth', 'MentHlth','GenHlth','Income']\n",
        "categorical_features = ['Sex', 'HighBP', 'HighChol', 'CholCheck', 'Smoker', 'Stroke', 'PhysActivity', 'Fruits', 'Veggies', 'Diabetes', 'HvyAlcoholConsump', 'AnyHealthcare', 'NoDocbcCost', 'DiffWalk']\n",
        "continuous_features = ['BMI']\n",
        "health = ['PhysActivity', 'Fruits', 'Veggies', 'NoDocbcCost']\n",
        "unhealth = ['HighBP', 'HighChol', 'CholCheck', 'Smoker', 'Stroke', 'Diabetes', 'HvyAlcoholConsump', 'AnyHealthcare']"
      ],
      "metadata": {
        "id": "OMoH-e43K-br"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inter = health + unhealth"
      ],
      "metadata": {
        "id": "92MXg-cULMv7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Prapare data\n",
        "  + Unbalanced\n",
        "  + balanced\n",
        "  + split data"
      ],
      "metadata": {
        "id": "hCCCAPPYLWBF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ EDA part, including dimensionality reduction"
      ],
      "metadata": {
        "id": "ydGhZJoP4t72"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "rmiH1VN-46c_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Split data into train_val and test\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_val, test = train_test_split(data, test_size = 0.2, stratify=data[target].values, random_state=0)\n",
        "\n",
        "X_train_val = train_val.drop(columns=[target])\n",
        "y_train_val = train_val[target]\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, stratify=y_train_val.values, test_size=0.2, random_state=0)\n",
        "X_test = test.drop(columns=[target])\n",
        "y_test = test[target]\n",
        "\n",
        "## Get balanced data\n",
        "from numpy.random import MT19937\n",
        "from numpy.random import RandomState, SeedSequence\n",
        "def under_sample(label, target):\n",
        "    rand_state = RandomState(MT19937(SeedSequence(123456789)))\n",
        "    target_usamp = target[target == label]\n",
        "    target_osamp = target[target != label]\n",
        "    resampled_idx = rand_state.choice(target_osamp.index, size=len(target_usamp))\n",
        "    \n",
        "    return resampled_idx\n",
        "\n",
        "rsp_idx = under_sample(1, y_train_val)\n",
        "data_balanced_0 = train_val.loc[rsp_idx, :]\n",
        "data_label_1 = train_val[y_train_val == 1]\n",
        "print(data_balanced_0.shape, data_label_1.shape)\n",
        "balanced_data = pd.concat([data_balanced_0, data_label_1], axis=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VlEZeRqULkO-",
        "outputId": "d197174b-1866-4fcd-ca69-553b40030114"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(19114, 22) (19114, 22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb"
      ],
      "metadata": {
        "id": "xqFs-IHOMHpy"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "def target_enc(df, cols, target):\n",
        "    X, y = df[cols], df[target]\n",
        "    skf = StratifiedKFold(n_splits=5, shuffle=True)\n",
        "    target_mean_features = []\n",
        "    for col in cols:\n",
        "        colname = col + '_target_mean'\n",
        "        target_mean_features.append(colname)\n",
        "        df[colname] = 0\n",
        "    for tr_idx, val_idx in skf.split(X,y):\n",
        "        X_train, X_val = df.iloc[tr_idx], df.iloc[val_idx]\n",
        "        for col in cols:\n",
        "            mean = X_train.groupby(by=col)[target].mean()\n",
        "            df[col+'_target_mean'].iloc[val_idx] = X_val[col].map(mean)\n",
        "    prior = df[target].mean()\n",
        "    df[target_mean_features].fillna(prior, inplace=True)\n",
        "    \n",
        "    \n",
        "    #regularization\n",
        "    \n",
        "    for feature in target_mean_features:\n",
        "        df[feature] = df[feature] * len(df) + df[feature].nunique() * prior\n",
        "        df[feature] = df[feature] / (len(df) + df[feature].nunique())\n",
        "    return df[target_mean_features]\n",
        "\n",
        "def prepare_train(train, target):\n",
        "    train['sumHealth'] = train[health].sum(axis=1)\n",
        "    train['sumUnhealth'] = train[unhealth].sum(axis=1)\n",
        "    train['diff_health'] = train['sumHealth'] - train['sumUnhealth']\n",
        "\n",
        "    ## Label encoding and interactive labels\n",
        "    features_mean_enc = categorical_features\n",
        "    mean_enc_cat = target_enc(train[categorical_features+[target]], categorical_features, target)\n",
        "    #mean_enc_ord = target_enc(train[ordinal_features + [target]], ordinal_features, target)\n",
        "    \n",
        "    train = pd.concat([train.drop(columns=features_mean_enc), mean_enc_cat], axis=1)\n",
        "    \n",
        "    for i in inter:\n",
        "      for j in inter:\n",
        "        if i!=j:\n",
        "          train[i+'|'+j] = train[i+'_target_mean'] * train[j+'_target_mean']\n",
        "\n",
        "            \n",
        "    return train\n",
        "\n",
        "\n",
        "def prepare_test(test, train, target):\n",
        "    test['sumHealth'] = test[health].sum(axis=1)\n",
        "    test['sumUnhealth'] = test[unhealth].sum(axis=1)\n",
        "    test['diff_health'] = test['sumHealth'] - test['sumUnhealth']\n",
        "    \n",
        "    features_to_enc = categorical_features\n",
        "    for feature in features_to_enc:\n",
        "        test[feature + '_target_mean'] = test[feature].map(train.groupby(by=feature)[target].mean())\n",
        "        \n",
        "    prior = train[target].mean()\n",
        "    test[features_to_enc].fillna(prior, inplace=True)\n",
        "    \n",
        "    #Smooth\n",
        "    for feature in features_to_enc:\n",
        "        test[feature] = test[feature] * len(test) + test[feature].nunique() * prior\n",
        "        test[feature] = test[feature] / (len(test) + test[feature].nunique())\n",
        "    \n",
        "    for i in inter:\n",
        "      for j in inter:\n",
        "        if i!=j:\n",
        "          test[i+'|'+j] = test[i+'_target_mean'] * test[j+'_target_mean']\n",
        "    \n",
        "    test = test.drop(columns=features_to_enc)\n",
        "    return test\n",
        "\n",
        "def prepare(train_val, X_test, y_test, target):\n",
        "    train = prepare_train(train_val, target)\n",
        "    X_train, X_val, y_train, y_val = train_test_split(train.drop(columns=[target]), train[target], test_size=0.1)\n",
        "    test = pd.concat([X_test, y_test], axis=1)\n",
        "    test_set = prepare_test(test, train_val, target)\n",
        "    X_test_ = test_set.drop(columns=[target])\n",
        "    y_test_ = test_set[target]\n",
        "\n",
        "\n",
        "    return X_train, X_val, y_train, y_val, X_test_, y_test_"
      ],
      "metadata": {
        "id": "RRpWX4ZKNHYV"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_, X_val_, y_train_, y_val_, X_test_, y_test_ = prepare(balanced_data, X_test, y_test, target)"
      ],
      "metadata": {
        "id": "4C2b3iQWO0N9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### We use label encoding and interactive features and see improvement on SVC LogisticRegression and RandomForest"
      ],
      "metadata": {
        "id": "R8R1hkdjM1j2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "clfs = [SVC(), RandomForestClassifier(), LogisticRegression()]\n",
        "\n",
        "X_ = pd.concat([X_train_, X_val_], axis=0)\n",
        "y_ = pd.concat([y_train_, y_val_], axis=0)\n",
        "for clf in clfs:\n",
        "  clf.fit(X_train_, y_train_)\n",
        "  print('{} score on val is {}' .format(clf.__class__.__name__, clf.score(X_val_, y_val_)))\n",
        "  clf.fit(X_, y_)\n",
        "  print('{} score on test is {}' .format(clf.__class__.__name__, clf.score(X_test_, y_test_)))\n",
        "  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVlNNB51NDO6",
        "outputId": "288a8138-3cc8-489f-8a82-3610214a0173"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVC score on val is 0.7590897201150929\n",
            "SVC score on test is 0.6995230211289813\n",
            "RandomForestClassifier score on val is 0.7501961810096782\n",
            "RandomForestClassifier score on test is 0.7258751182592242\n",
            "LogisticRegression score on val is 0.7637980643473712\n",
            "LogisticRegression score on test is 0.7411896877956481\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "X_train_u, X_val_u, y_train_u, y_val_u, X_test_, y_test_ = prepare(train_val, X_test, y_test, target)\n",
        "clfs = [RandomForestClassifier(), LogisticRegression()]\n",
        "\n",
        "X_u = pd.concat([X_train_u, X_val_u], axis=0)\n",
        "y_u = pd.concat([y_train_u, y_val_u], axis=0)\n",
        "for clf in clfs:\n",
        "  clf.fit(X_u, y_u)\n",
        "  print('{} score on test is {}' .format(clf.__class__.__name__, clf.score(X_test_, y_test_)))\n",
        "  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8MifxunRjCk",
        "outputId": "1a69e12b-eb7e-47bb-fccb-99c0934c7ac0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier score on test is 0.9067131819615263\n",
            "LogisticRegression score on test is 0.9068314411857458\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "params = {'boosting_type': 'gbdt', 'objective': 'binary', 'n_estimators':200,\n",
        "              'num_leaves': 200, 'learning_rate': 0.05, 'max_bin': 512, 'max_depth' : 10, \n",
        "              'subsample_for_bin': 200, 'subsample': 1, 'subsample_freq': 1,\n",
        "              'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'reg_alpha': 5, 'reg_lambda': 2, \n",
        "              'metric': 'auc'}"
      ],
      "metadata": {
        "id": "8w0MBEy2WY0q"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ Run a model on imbalanced data\n",
        "+ Accuracy and recall"
      ],
      "metadata": {
        "id": "YnEB9Q984IdX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Q_RPwwjUt1h1"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ Run a model on balanced data\n",
        "+ Accuracy and recall"
      ],
      "metadata": {
        "id": "UfFR5v2D4TyH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "2Pc-LCmW4bkD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ "
      ],
      "metadata": {
        "id": "tcaPFrAJ4dyp"
      }
    }
  ]
}